\chapter{Related Work}
\label{sec:related}

We now discuss related work not covered so far.

\section{FHE accelerators}
Prior work has proposed accelerators for individual FHE operations, but not full FHE computations~\cite{cousins:hpec12:sipher-fpga,cousins:hpec14:fpga-he,cousins:tetc17:fpga-he,doroz:tc15:accelerating-fhe,roy:hpca19:fpga-he,mert:tvlsi20:bfv-accel,migliore:tecs17:he-karatsuba,riazi:asplos20:heax,turan:tc20:heaws,mert:tvlsi20:bfv-accel}.
These designs target FPGAs and rely on a host processor;
\autoref{sec:fhe_analysis} discussed their limitations.
Early designs accelerated small primitives like NTTs, and were dominated by host-FPGA communication.
State-of-the-art accelerators execute a full homomorphic multiplication independently:
Roy et al.~\cite{roy:hpca19:fpga-he} accelerate B/FV multiplication by 13$\times$ over a CPU;
% dsm: HEAWS is amazingly obtuse on not reporting mult throughput; I'll just
% take their end-to-end speedup on the ANN, which is "why did you bother" bad
HEAWS~\cite{turan:tc20:heaws} accelerates B/FV multiplication, and uses it to speed a simple 
benchmark by 5$\times$;
and HEAX~\cite{riazi:asplos20:heax} accelerates CKKS multiplication and key-switching by up to 200$\times$.
These designs suffer high data movement (e.g., HEAX does not reuse key-switch hints)
and use fixed pipelines with relatively low-throughput FUs.

We have shown that accelerating FHE programs requires a different approach:
data movement becomes the key constraint, requiring new techniques
to extract reuse {across} homomorphic operations;
and fixed pipelines cannot support the operations of even a single benchmark.
Instead, \name achieves flexibility and high performance by exploiting
wide-vector execution with high-throughput FUs.
This lets \name execute not only full applications, but different FHE schemes.

% dsm: RNS/Karatsuba tradeoffs
%Most prior accelerators use RNS representation (\autoref{sec:fhe_optimizations})
%to avoid wide arithmetic, and \name does too.
%Migliore et al. ...
% dsm: ehhhhh, nope, WTF. What is this accelerator even doing? I though it was using Karatsuba for wide arithmetic, but it's uing Karatsuba for polynomial multiplication instead of the NTT! Basically for the case where there are no actual benefits. ~2x speedup over NFlib.
% Well, in this case I just don't know of anything that's implementing wide arithmetic. So we may as well not discuss it.

\section{Hybrid HE-MPC accelerators} \label{sec:mpc}
Recent work has also proposed ASIC accelerators for some homomorphic encryption primitives
in the context of oblivious neural networks~\cite{juvekar2018gazelle,reagen:hpca21:cheetah}.
These approaches are very different from FHE:
they combine homomorphic encryption with multi-party computation (MPC),
executing a single layer of the network at a time and sending intermediates
to the client, which computes the final activations.
Gazelle~\cite{juvekar2018gazelle} is a low-power ASIC for homomorphic evaluations,
and Cheetah~\cite{reagen:hpca21:cheetah} introduces algorithmic optimizations
and a large ASIC design that achieves very large speedups over Gazelle.

These schemes avoid high-depth FHE programs, so server\hyp{}side homomorphic operations are cheaper.
But they are limited by client-side computation and client-server communication.
CHOCO~\cite{vanderhagen:arxiv21:choco} shows that client-side computation costs are substantial,
and when they are accelerated, network latency and throughput overheads dominate
(several seconds per DNN inference).
By contrast, \name enables offloading the full inference using FHE,
avoiding frequent communication.

\section{GPU acceleration}
Finally, prior work has also used GPUs to accelerate different FHE schemes,
including GH~\cite{wang:hpec12:fhe-gpu,wang:tc13:fhe-gpu}, BGV~\cite{wang:iscas14:leveled-gpu},
and B/FV~\cite{al:emerging19:implementation}.
Though GPUs have plentiful compute and bandwidth,
they lack modular arithmetic, their pure data-parallel approach
makes non-element-wise operations like NTTs expensive,
and their small on-chip storage adds data movement.
As a result, GPUs achieve only modest performance gains.
For instance, Badawi et al.~\cite{al:emerging19:implementation}
accelerate B/FV multiplication using GPUs, and achieve speedups of around 10$\times$ to 100$\times$
over single-thread CPU execution.
